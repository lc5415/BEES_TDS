output = t(parApply(clust, v, MARGIN=1,
FUN=function(k){
j=k[2];i=k[1]
model = lm(proteins[,i]~tr[,j])
BetasP2[i,j] = coef(model)[2]
PvaluesP2[i,j] = summary(model)$coefficients[2,4]
return(c(BetasP2[i,j], PvaluesP2[i,j]))
}))
stopCluster(clust)
BetasP2 = output[,1]
PvaluesP2 = output[,2]
dim(BetasP2) = dim(PvaluesP2) = c(ncol(proteins), ncol(tr))
})
knitr::opts_knit$set(root.dir = "/Users/luischavesrodriguez/OneDrive\ -\ Imperial\ College\ London/MScHDA/Term2/CompEpi/06-practical/")
proteins = readRDS("Data/proteins_denoised.rds")
tr = readRDS("Data/transcripts_infl_denoised.rds")
covars = readRDS("Data/covariates.rds")
annot_tr = readRDS("Data/annotation_transcripts_infl.rds")
Betas = Pvalues = BetasP = PvaluesP = BetasP2 = PvaluesP2 = BetasP3 = PvaluesP3 = matrix(data = NA, nrow = ncol(proteins), ncol = ncol(tr))
library(parallel)
library(plyr)
library(purrr)
# barbara's parallel method for nested loops
system.time({
no_cores <- detectCores()-1
clust <- makeCluster(no_cores, type='FORK')
v=expand.grid(1:ncol(proteins), 1:ncol(tr))
output = t(parApply(clust, v, MARGIN=1,
FUN=function(k){
j=k[2];i=k[1]
model = lm(proteins[,i]~tr[,j])
BetasP2[i,j] = coef(model)[2]
PvaluesP2[i,j] = summary(model)$coefficients[2,4]
return(c(BetasP2[i,j], PvaluesP2[i,j]))
}))
stopCluster(clust)
BetasP2 = output[,1]
PvaluesP2 = output[,2]
dim(BetasP2) = dim(PvaluesP2) = c(ncol(proteins), ncol(tr))
})
# barbara's parallel method but with mapply
system.time({
no_cores <- detectCores()-1
clust <- makeCluster(no_cores, type='FORK')
v=expand.grid(1:ncol(proteins), 1:ncol(tr))
#v=expand.grid(1:ncol(proteins), 1:ncol(tr))
output = clusterMap(cl = clust,
fun = function(i, j) {
# This is where expensive operations should go
model = lm(proteins[,i]~tr[,j])
BetasP3[i,j] = coef(model)[2]
PvaluesP3[i,j] = summary(model)$coefficients[2,4]
return(c(BetasP3[i,j], PvaluesP3[i,j]))
}, v$Var1, v$Var2)
# need to use dim to put it back in right shape
# dim() = c(ncol(proteins), ncol(tr))
stopCluster(clust)
BetasP3 = sapply(output, "[[", 1)
PvaluesP3 = sapply(output, "[[", 2)
dim(BetasP3) = dim(PvaluesP3) = c(ncol(proteins), ncol(tr))
})
# trying to parallelise this
library(foreach)
library(doParallel)
system.time({
cl<-makeCluster(detectCores()-1, type = "FORK")
registerDoParallel(cl)
x <- foreach(i = 1:ncol(proteins), .combine = 'cbind') %:%
foreach(j = 1:ncol(tr), .combine = 'c') %dopar% {
model = lm(proteins[,i]~tr[,j])
BetasP[i,j] = coef(model)[2]
PvaluesP[i,j] = summary(model)$coefficients[2,4]
#assign(BetasP[i,j], coef(model)[2], env = .GlobalEnv)
#assign(PvaluesP[i,j], summary(model)$coefficients[2,4],
#env = .GlobalEnv)
}
stopCluster(cl)
stopImplicitCluster()
})
system.time({
for (i in 1:ncol(proteins)){
for (j in 1:ncol(tr)){
model = lm(proteins[,i]~tr[,j])
Betas[i,j] = coef(model)[2]
Pvalues[i,j] = summary(model)$coefficients[2,4]
}
}
})
rownames(Betas) = rownames(Pvalues) = colnames(proteins)
colnames(Betas) = colnames(Pvalues) = colnames(tr)
number_of_tests = ncol(proteins)*ncol(tr)
number_of_tests
# NUMBER OF BONFERRONI SIGNIFICANTS
sum(p.adjust(as.vector(Pvalues), method = "bonf")<0.05)
# NUMBER OF BENJAMINI SIGNIFICANTS
sum(p.adjust(as.vector(Pvalues), method = "BH")<0.05)
# NUMBER OF UNADJUSTED SIGNIFICANT
sum(p.adjust(as.vector(Pvalues), method = "none")<0.05)
to_keep = p.adjust(Pvalues, method = "BH")<0.05
dim(to_keep) = dim(Pvalues)
pairs = which(to_keep,arr.ind = TRUE)
mytable = table(colnames(proteins)[pairs[, 1]],
annot_tr[colnames(tr)[pairs[,2]], "gene_symbol"])
suppressPackageStartupMessages(sapply(c("ggnet", "network", "sna","ggplot2"),
FUN = library, character.only = T))
edges = data.frame(proteins = colnames(proteins)[pairs[, 1]],
transcripts = colnames(tr)[pairs[, 2]])
net = network(edges)
ggnet2(net, label = T, color = "grey", label.color = "red")
set.seed(1)
n = 100 # number of observations
X1 = rnorm(n)
X2 = rnorm(n)
beta1 = 1
beta2 = 1.2
sigma = 0.5
epsilon = rnorm(n, sd = sigma)
Y = beta1 * X1 + beta2 * X2 + epsilon
library(plotly)
plot_ly(data.frame(Y,X1,X2), x = ~X1, y = ~X2, z = ~Y)
model1 = lm(Y~X1)
model2 = lm(Y~X2)
summary(model1)
summary(model2)
ExtractPval = function(model) {
f = summary(model)$fstatistic
return(pf(f[1], f[2], f[3], lower.tail = FALSE)) }
pval_univ1 = ExtractPval(model1)
pval_univ2 = ExtractPval(model2)
model = lm(Y ~ X1 + X2)
summary(model)
pval_multiv = ExtractPval(model)
pvals = c(pval_univ1, pval_univ2, pval_multiv)
names(pvals) = c("X1 only", "X2 only", "Both X1 and X2")
print(pvals)
par(mfrow = c(1, 3), las = 1, col = "navy")
plot(model1$fitted.values, Y, pch = 19)
plot(model2$fitted.values, Y, pch = 19)
plot(model$fitted.values, Y, pch = 19)
summary(model)$coefficients
library(glmnet)
prot.tr = merge(proteins, tr, by = "row.names")
lassoSequence = function(protein,
bestlam = "lambda.1se",
extract.betas = 0){
cv = cv.glmnet(x = as.matrix(prot.tr[,colnames(tr)]),
y = as.matrix(prot.tr[,protein]),
family = "gaussian", type.measure = "default", alpha = 1,
nfolds = 10)
if (extract.betas == 0){
return(sum(coef(cv, s = bestlam)!=0))
}
if (extract.betas == 1){
tmp_coeffs = coef(cv, s = bestlam)
return(data.frame(name = tmp_coeffs@Dimnames[[1]][tmp_coeffs@i + 1],
coefficient = tmp_coeffs@x))
}
}
## running this heavy thing in parallel
library(parallel)
# when using FORK variable can be exported from computer to Cluster
cl = makeCluster(detectCores()-1, type = "FORK")
t0 = Sys.time()
num_of_trans = unlist(parLapply(cl = cl, colnames(proteins),lassoSequence))
stopCluster(cl)
print(Sys.time()-t0)
## running this heavy thing sequentially
t0 = Sys.time()
num_of_trans = unlist(lapply(colnames(proteins),lassoSequence))
print(Sys.time()-t0)
tr_per_prot = data.frame(NumberOfTranscripts = num_of_trans,
protein = colnames(proteins))
ggplot(tr_per_prot, aes(x = reorder(protein, -NumberOfTranscripts), y = NumberOfTranscripts))+geom_col()+theme(axis.text.x = element_text(angle = 90, hjust = 1))
# when using FORK variable can be exported from computer to Cluster
cl = makeCluster(detectCores()-1, type = "FORK")
t0 = Sys.time()
num_of_trans = unlist(parLapply(cl = cl, colnames(proteins),lassoSequence))
tr_per_prot = data.frame(NumberOfTranscripts = unlist(
parLapply(colnames(proteins),
function(x) lassoSequence(x, "lambda.min"))),
protein = colnames(proteins))
# when using FORK variable can be exported from computer to Cluster
cl = makeCluster(detectCores()-1, type = "FORK")
# when using FORK variable can be exported from computer to Cluster
cl = makeCluster(detectCores()-1, type = "FORK")
t0 = Sys.time()
tr_per_prot = data.frame(NumberOfTranscripts = unlist(
parLapply(cl = cl,colnames(proteins),
function(x) lassoSequence(x, "lambda.min"))),
protein = colnames(proteins))
knitr::opts_knit$set(root.dir = "/Users/luischavesrodriguez/OneDrive\ -\ Imperial\ College\ London/MScHDA/Term2/CompEpi/06-practical/")
proteins = readRDS("Data/proteins_denoised.rds")
tr = readRDS("Data/transcripts_infl_denoised.rds")
covars = readRDS("Data/covariates.rds")
annot_tr = readRDS("Data/annotation_transcripts_infl.rds")
Betas = Pvalues = BetasP = PvaluesP = BetasP2 = PvaluesP2 = BetasP3 = PvaluesP3 = matrix(data = NA, nrow = ncol(proteins), ncol = ncol(tr))
library(parallel)
library(plyr)
library(purrr)
# barbara's parallel method for nested loops
system.time({
no_cores <- detectCores()-1
clust <- makeCluster(no_cores, type='FORK')
v=expand.grid(1:ncol(proteins), 1:ncol(tr))
output = t(parApply(clust, v, MARGIN=1,
FUN=function(k){
j=k[2];i=k[1]
model = lm(proteins[,i]~tr[,j])
BetasP2[i,j] = coef(model)[2]
PvaluesP2[i,j] = summary(model)$coefficients[2,4]
return(c(BetasP2[i,j], PvaluesP2[i,j]))
}))
stopCluster(clust)
BetasP2 = output[,1]
PvaluesP2 = output[,2]
dim(BetasP2) = dim(PvaluesP2) = c(ncol(proteins), ncol(tr))
})
# barbara's parallel method but with mapply
system.time({
no_cores <- detectCores()-1
clust <- makeCluster(no_cores, type='FORK')
v=expand.grid(1:ncol(proteins), 1:ncol(tr))
#v=expand.grid(1:ncol(proteins), 1:ncol(tr))
output = clusterMap(cl = clust,
fun = function(i, j) {
# This is where expensive operations should go
model = lm(proteins[,i]~tr[,j])
BetasP3[i,j] = coef(model)[2]
PvaluesP3[i,j] = summary(model)$coefficients[2,4]
return(c(BetasP3[i,j], PvaluesP3[i,j]))
}, v$Var1, v$Var2)
# need to use dim to put it back in right shape
# dim() = c(ncol(proteins), ncol(tr))
stopCluster(clust)
BetasP3 = sapply(output, "[[", 1)
PvaluesP3 = sapply(output, "[[", 2)
dim(BetasP3) = dim(PvaluesP3) = c(ncol(proteins), ncol(tr))
})
# trying to parallelise this
library(foreach)
library(doParallel)
system.time({
cl<-makeCluster(detectCores()-1, type = "FORK")
registerDoParallel(cl)
x <- foreach(i = 1:ncol(proteins), .combine = 'cbind') %:%
foreach(j = 1:ncol(tr), .combine = 'c') %dopar% {
model = lm(proteins[,i]~tr[,j])
BetasP[i,j] = coef(model)[2]
PvaluesP[i,j] = summary(model)$coefficients[2,4]
#assign(BetasP[i,j], coef(model)[2], env = .GlobalEnv)
#assign(PvaluesP[i,j], summary(model)$coefficients[2,4],
#env = .GlobalEnv)
}
stopCluster(cl)
stopImplicitCluster()
})
system.time({
for (i in 1:ncol(proteins)){
for (j in 1:ncol(tr)){
model = lm(proteins[,i]~tr[,j])
Betas[i,j] = coef(model)[2]
Pvalues[i,j] = summary(model)$coefficients[2,4]
}
}
})
rownames(Betas) = rownames(Pvalues) = colnames(proteins)
colnames(Betas) = colnames(Pvalues) = colnames(tr)
number_of_tests = ncol(proteins)*ncol(tr)
number_of_tests
# NUMBER OF BONFERRONI SIGNIFICANTS
sum(p.adjust(as.vector(Pvalues), method = "bonf")<0.05)
# NUMBER OF BENJAMINI SIGNIFICANTS
sum(p.adjust(as.vector(Pvalues), method = "BH")<0.05)
# NUMBER OF UNADJUSTED SIGNIFICANT
sum(p.adjust(as.vector(Pvalues), method = "none")<0.05)
to_keep = p.adjust(Pvalues, method = "BH")<0.05
dim(to_keep) = dim(Pvalues)
pairs = which(to_keep,arr.ind = TRUE)
mytable = table(colnames(proteins)[pairs[, 1]],
annot_tr[colnames(tr)[pairs[,2]], "gene_symbol"])
suppressPackageStartupMessages(sapply(c("ggnet", "network", "sna","ggplot2"),
FUN = library, character.only = T))
edges = data.frame(proteins = colnames(proteins)[pairs[, 1]],
transcripts = colnames(tr)[pairs[, 2]])
net = network(edges)
ggnet2(net, label = T, color = "grey", label.color = "red")
set.seed(1)
n = 100 # number of observations
X1 = rnorm(n)
X2 = rnorm(n)
beta1 = 1
beta2 = 1.2
sigma = 0.5
epsilon = rnorm(n, sd = sigma)
Y = beta1 * X1 + beta2 * X2 + epsilon
library(plotly)
plot_ly(data.frame(Y,X1,X2), x = ~X1, y = ~X2, z = ~Y)
model1 = lm(Y~X1)
model2 = lm(Y~X2)
summary(model1)
summary(model2)
ExtractPval = function(model) {
f = summary(model)$fstatistic
return(pf(f[1], f[2], f[3], lower.tail = FALSE)) }
pval_univ1 = ExtractPval(model1)
pval_univ2 = ExtractPval(model2)
model = lm(Y ~ X1 + X2)
summary(model)
pval_multiv = ExtractPval(model)
pvals = c(pval_univ1, pval_univ2, pval_multiv)
names(pvals) = c("X1 only", "X2 only", "Both X1 and X2")
print(pvals)
par(mfrow = c(1, 3), las = 1, col = "navy")
plot(model1$fitted.values, Y, pch = 19)
plot(model2$fitted.values, Y, pch = 19)
plot(model$fitted.values, Y, pch = 19)
summary(model)$coefficients
library(glmnet)
prot.tr = merge(proteins, tr, by = "row.names")
lassoSequence = function(protein,
bestlam = "lambda.1se",
extract.betas = 0){
cv = cv.glmnet(x = as.matrix(prot.tr[,colnames(tr)]),
y = as.matrix(prot.tr[,protein]),
family = "gaussian", type.measure = "default", alpha = 1,
nfolds = 10)
if (extract.betas == 0){
return(sum(coef(cv, s = bestlam)!=0))
}
if (extract.betas == 1){
tmp_coeffs = coef(cv, s = bestlam)
return(data.frame(name = tmp_coeffs@Dimnames[[1]][tmp_coeffs@i + 1],
coefficient = tmp_coeffs@x))
}
}
## running this heavy thing in parallel
library(parallel)
# when using FORK variable can be exported from computer to Cluster
cl = makeCluster(detectCores()-1, type = "FORK")
t0 = Sys.time()
num_of_trans = unlist(parLapply(cl = cl, colnames(proteins),lassoSequence))
stopCluster(cl)
print(Sys.time()-t0)
## running this heavy thing sequentially
t0 = Sys.time()
num_of_trans = unlist(lapply(colnames(proteins),lassoSequence))
print(Sys.time()-t0)
tr_per_prot = data.frame(NumberOfTranscripts = num_of_trans,
protein = colnames(proteins))
ggplot(tr_per_prot, aes(x = reorder(protein, -NumberOfTranscripts), y = NumberOfTranscripts))+geom_col()+theme(axis.text.x = element_text(angle = 90, hjust = 1))
# when using FORK variable can be exported from computer to Cluster
cl = makeCluster(detectCores()-1, type = "FORK")
t0 = Sys.time()
tr_per_prot = data.frame(NumberOfTranscripts = unlist(
parLapply(cl = cl,colnames(proteins),
function(x) lassoSequence(x, "lambda.min"))),
protein = colnames(proteins))
stopCluster(cl)
print(Sys.time()-t0)
ggplot(tr_per_prot, aes(x = reorder(protein, -NumberOfTranscripts), y = NumberOfTranscripts))+geom_col()+theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(tr_per_prot, aes(x = reorder(protein, -NumberOfTranscripts), y = NumberOfTranscripts))+geom_col()+theme(axis.text.x = element_text(angle = 90, hjust = 1))
source('~/OneDrive - Imperial College London/MScHDA/Term2/CompEpi/07-practical/practical7.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
.SavedPlots
.Savedplots
.SavedPlots
plts = .SavedPlots
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
library(impute)
source('~/OneDrive - Imperial College London/MScHDA/Term2/CompEpi/07-practical/practical7.R', echo=TRUE)
out = Calibrate(data = mydatastatus, method = "EstimationSelection",
implementation = "pcor.shrink", PFER_thr = myPFER, pk = mypk)
myPFER
dim(mydatastatus)
out = Calibrate(data = mydatastatus, PFER_thr = myPFER, pk = mypk)
out$PFER
## GRAPH
# Calibrated adjacency matrix
A = GetAdjacency(out, pk = mypk)
# Network visualisation
mynodecolor = c(rep("skyblue", ncol(cpg)), rep("tomato",ncol(tr)))
names(mynodecolor) = c(colnames(cpg), colnames(tr))
g = GetGraph(adjacency = A, node_color = mynodecolor)
V(g)$label = annot[V(g)$name, "alt.name"]
par(mar = rep(0, 4))
set.seed(1)
plot(g, layout = layout_with_fr(g))
banner("BIO")
library(bannerCommenter)
banner("Bio KNN imputation", emph = T)
banner("log Bio KNN imputation", emph = T)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
results
results = t(sapply(1:5,
function(x) kNNImputeOptimization(bio, seed = x,
perParam = T, scaled = T,
plot = x==5)))
source("kNNImputeOptimization.R",print.eval = T)
results = t(sapply(1:5,
function(x) kNNImputeOptimization(bio, seed = x,
perParam = T, scaled = T,
plot = x==5)))
results = t(sapply(1:5,
function(x) kNNImputeOptimization(bio, seed = x,
perParam = T, scaled = T,
plot = x==5)))
results = t(sapply(1:5,
function(x) kNNImputeOptimization(bio, seed = x,
perParam = T, scaled = T,
plot = x==5)))
factplot = MSEperParam %>% pivot_longer(-k) %>%
ggplot(aes(x = k, y = value))+
facet_wrap(~name)+geom_point()
debugSource('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/kNNImputeOptimization.R', echo=TRUE)
results = t(sapply(1:5,
function(x) kNNImputeOptimization(bio, seed = x,
perParam = T, scaled = T,
plot = x==5)))
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
View(results)
factplot = results[[5]][[2]]
bplot = results[[5]][[3]]
scatplot = results[[5]][[4]]
RMSE = results[[1]]
View(results)
View(results)
View(results[[1]])
View(results[[5]][[1]])
RMSE = data.frame()
RMSE = data.frame()
for (i in 1:CV){
if (i != CV){
RMSE = cbind(RMSE, results[[i]])
} else{
RMSE = cbind(RMSE, results[[CV]][[i]])
}
}
CV = 5
RMSE = data.frame()
for (i in 1:CV){
if (i != CV){
RMSE = cbind(RMSE, results[[i]])
} else{
RMSE = cbind(RMSE, results[[CV]][[i]])
}
}
RMSE = results[[1]]
for (i in 2:CV){
if (i != CV){
RMSE = cbind(RMSE, results[[i]])
} else{
RMSE = cbind(RMSE, results[[CV]][[i]])
}
}
View(results)
View(RMSE)
results[[5]][[1]]
RMSE = cbind(RMSE, results[[CV]][[i]])
RMSE = cbind(RMSE, results[[CV]][[i]])
CV
length(results[[5]][[1]])
RMSE = cbind(RMSE, results[[CV]][[1]])
RMSE = t(RMSE)
factplot = results[[2]]
bplot = results[[3]]
scatplot = results[[4]]
View(RMSE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
RMSE = data.frame()
for (i in 1:CV){
if (i != CV){
RMSE = cbind(RMSE, results[[i]])
} else{
RMSE = cbind(RMSE, results[[CV]][[1]])
}
}
results
View(results)
RMSE = data.frame()
for (i in 1:CV){
if (i != CV){
RMSE = cbind(RMSE, results[[i]])
} else{
RMSE = cbind(RMSE, results[[CV]][[1]])
}
}
i
RMSE = results[[1]]
for (i in 2:CV){
if (i != CV){
RMSE = cbind(RMSE, results[[i]])
} else{
RMSE = cbind(RMSE, results[[CV]][[1]])
}
}
RMSE = t(RMSE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source('~/OneDrive - Imperial College London/MScHDA/Term2/TDS/Project/Scripts/knnImputaion.R', echo=TRUE)
source("kNNImputeOptimization.R",print.eval = T)
CV = 5
results = t(sapply(1:CV,
function(x) kNNImputeOptimization(bio, seed = x,
perParam = T, scaled = T,
plot = x==CV)))
